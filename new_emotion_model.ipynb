{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Classification Model - IPYNB\n",
    "\n",
    "pip install numpy tensorflow scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "l2_strength = 0.001  # L2 regularization strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modify this based on the path of the training & testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "train_dir = 'C:/Users/Melvin Tang/OneDrive/Codes/I2ML/FINALPRO/archive/train'\n",
    "\n",
    "test_dirs = [\n",
    "    'C:/Users/Melvin Tang/OneDrive/Codes/I2ML/FINALPRO/archive/testgeli',\n",
    "    'C:/Users/Melvin Tang/OneDrive/Codes/I2ML/FINALPRO/archive/testkevin',\n",
    "    'C:/Users/Melvin Tang/OneDrive/Codes/I2ML/FINALPRO/archive/test'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20011 images belonging to 5 classes.\n",
      "Found 5000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=17,\n",
    "    horizontal_flip=True, \n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode='rgb',  # Keeping RGB as in your original code\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories for the classes\n",
    "categories = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Compute Class Weights\n",
    "labels = train_generator.classes\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "model = models.Sequential([\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength), input_shape=(48, 48, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),  # Reduced dropout rate\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),  # Reduced dropout rate\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),  # Reduced dropout rate\n",
    "\n",
    "    # Fourth Convolutional Block (Added)\n",
    "    layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.5),  # Maintained dropout rate\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(l2_strength)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),  # Reduced dropout rate\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Compiling, Loss Functions and Callbacks \n",
    "(Utilized early stopping and learning rate reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)  # Reduced learning rate\n",
    "\n",
    "# Using label smoothing\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "626/626 [==============================] - 209s 321ms/step - loss: 6.1923 - accuracy: 0.2250 - val_loss: 5.0441 - val_accuracy: 0.3178 - lr: 5.0000e-04\n",
      "Epoch 2/75\n",
      "626/626 [==============================] - 19s 30ms/step - loss: 4.2858 - accuracy: 0.3159 - val_loss: 3.3090 - val_accuracy: 0.4196 - lr: 5.0000e-04\n",
      "Epoch 3/75\n",
      "626/626 [==============================] - 19s 30ms/step - loss: 2.8745 - accuracy: 0.4227 - val_loss: 2.4118 - val_accuracy: 0.3912 - lr: 5.0000e-04\n",
      "Epoch 4/75\n",
      "626/626 [==============================] - 21s 33ms/step - loss: 2.1762 - accuracy: 0.4696 - val_loss: 1.9286 - val_accuracy: 0.4972 - lr: 5.0000e-04\n",
      "Epoch 5/75\n",
      "626/626 [==============================] - 23s 37ms/step - loss: 1.8634 - accuracy: 0.5041 - val_loss: 1.7763 - val_accuracy: 0.4812 - lr: 5.0000e-04\n",
      "Epoch 6/75\n",
      "626/626 [==============================] - 21s 33ms/step - loss: 1.7477 - accuracy: 0.5200 - val_loss: 1.6885 - val_accuracy: 0.5088 - lr: 5.0000e-04\n",
      "Epoch 7/75\n",
      "626/626 [==============================] - 18s 29ms/step - loss: 1.7000 - accuracy: 0.5211 - val_loss: 1.7229 - val_accuracy: 0.4878 - lr: 5.0000e-04\n",
      "Epoch 8/75\n",
      "626/626 [==============================] - 18s 29ms/step - loss: 1.6977 - accuracy: 0.5232 - val_loss: 1.6786 - val_accuracy: 0.5116 - lr: 5.0000e-04\n",
      "Epoch 9/75\n",
      "626/626 [==============================] - 18s 29ms/step - loss: 1.6861 - accuracy: 0.5341 - val_loss: 1.7125 - val_accuracy: 0.4638 - lr: 5.0000e-04\n",
      "Epoch 10/75\n",
      "626/626 [==============================] - 18s 29ms/step - loss: 1.6705 - accuracy: 0.5410 - val_loss: 1.8695 - val_accuracy: 0.3724 - lr: 5.0000e-04\n",
      "Epoch 11/75\n",
      "626/626 [==============================] - 21s 33ms/step - loss: 1.6600 - accuracy: 0.5356 - val_loss: 1.6881 - val_accuracy: 0.5048 - lr: 5.0000e-04\n",
      "Epoch 12/75\n",
      "626/626 [==============================] - 23s 37ms/step - loss: 1.6670 - accuracy: 0.5332 - val_loss: 1.6868 - val_accuracy: 0.4736 - lr: 5.0000e-04\n",
      "Epoch 13/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.6511 - accuracy: 0.5416 - val_loss: 1.7165 - val_accuracy: 0.4954 - lr: 5.0000e-04\n",
      "Epoch 14/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.5449 - accuracy: 0.5695 - val_loss: 1.4804 - val_accuracy: 0.5660 - lr: 2.5000e-04\n",
      "Epoch 15/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4954 - accuracy: 0.5789 - val_loss: 1.5339 - val_accuracy: 0.5162 - lr: 2.5000e-04\n",
      "Epoch 16/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4799 - accuracy: 0.5859 - val_loss: 1.5503 - val_accuracy: 0.5166 - lr: 2.5000e-04\n",
      "Epoch 17/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4663 - accuracy: 0.5959 - val_loss: 1.4080 - val_accuracy: 0.5868 - lr: 2.5000e-04\n",
      "Epoch 18/75\n",
      "626/626 [==============================] - 21s 33ms/step - loss: 1.4561 - accuracy: 0.5975 - val_loss: 1.5456 - val_accuracy: 0.5068 - lr: 2.5000e-04\n",
      "Epoch 19/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4549 - accuracy: 0.5947 - val_loss: 1.4716 - val_accuracy: 0.5640 - lr: 2.5000e-04\n",
      "Epoch 20/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4481 - accuracy: 0.5998 - val_loss: 1.4446 - val_accuracy: 0.5578 - lr: 2.5000e-04\n",
      "Epoch 21/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4387 - accuracy: 0.6038 - val_loss: 1.4684 - val_accuracy: 0.5694 - lr: 2.5000e-04\n",
      "Epoch 22/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.4356 - accuracy: 0.6048 - val_loss: 1.4935 - val_accuracy: 0.5444 - lr: 2.5000e-04\n",
      "Epoch 23/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3742 - accuracy: 0.6291 - val_loss: 1.3212 - val_accuracy: 0.6200 - lr: 1.2500e-04\n",
      "Epoch 24/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3358 - accuracy: 0.6356 - val_loss: 1.3178 - val_accuracy: 0.6152 - lr: 1.2500e-04\n",
      "Epoch 25/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3277 - accuracy: 0.6392 - val_loss: 1.3755 - val_accuracy: 0.5866 - lr: 1.2500e-04\n",
      "Epoch 26/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3144 - accuracy: 0.6459 - val_loss: 1.3629 - val_accuracy: 0.5954 - lr: 1.2500e-04\n",
      "Epoch 27/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3089 - accuracy: 0.6479 - val_loss: 1.3394 - val_accuracy: 0.6084 - lr: 1.2500e-04\n",
      "Epoch 28/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.3037 - accuracy: 0.6481 - val_loss: 1.2971 - val_accuracy: 0.6202 - lr: 1.2500e-04\n",
      "Epoch 29/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.2955 - accuracy: 0.6523 - val_loss: 1.2934 - val_accuracy: 0.6280 - lr: 1.2500e-04\n",
      "Epoch 30/75\n",
      "626/626 [==============================] - 21s 34ms/step - loss: 1.2880 - accuracy: 0.6591 - val_loss: 1.2707 - val_accuracy: 0.6400 - lr: 1.2500e-04\n",
      "Epoch 31/75\n",
      "626/626 [==============================] - 22s 35ms/step - loss: 1.2845 - accuracy: 0.6583 - val_loss: 1.2637 - val_accuracy: 0.6414 - lr: 1.2500e-04\n",
      "Epoch 32/75\n",
      "138/626 [=====>........................] - ETA: 13s - loss: 1.2761 - accuracy: 0.6576"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=75,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def plot_accuracy(history):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(history)\n",
    "plot_loss(history)\n",
    "\n",
    "# Retrieve the final training and validation accuracy and loss\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "# Print the final training and validation accuracy and loss\n",
    "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a test data generator for a given directory\n",
    "def create_test_generator(test_dir):\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode='rgb',  # Keeping RGB as in your original code\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "# Evaluate the model on multiple test sets\n",
    "def evaluate_test_set(model, test_generator, test_dir, categories):\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(test_generator)\n",
    "    print(f'\\nTest Directory: {test_dir}')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    # Predictions and classification report\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=categories))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix for {os.path.basename(test_dir)}')\n",
    "    plt.show()\n",
    "\n",
    "# Loop through each test directory and evaluate\n",
    "for test_dir in test_dirs:\n",
    "    test_generator = create_test_generator(test_dir)\n",
    "    evaluate_test_set(model, test_generator, test_dir, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training your model or loading it\n",
    "model.save('C:/Users/LENOVO/Downloads/real-time-emotion-recognition/cnn_trial.h5')  # Save it as .h5 format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310MLGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
